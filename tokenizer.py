import regex

tokens = [
    ("WHITESPACE", r"\s+"),
    ("COMMENT", r"ğŸ’­.*?ğŸ’­"),
    ("BOOLEAN", r"âœ…|âŒ"),
    ("FLOAT", r'\d+\.\d+'),
    ("INTEGER", r"\d+"),
    ("OPERATOR", r"\+|-|/|\*|ğŸ”|â›”|ğŸ‹|ğŸ¢|ğŸ¬|ğŸŠ"),
    ("STRUCTURE", r"ğŸ™‚|ğŸ˜´|â¡ï¸|â¬…ï¸|â©|âª|â­ï¸|â®ï¸|ğŸ”„ï¸|ğŸš«|\(|\)|ğŸ’¡"),
    ("TYPE", r"âš™ï¸|ğŸ§µ|ğŸ§®|ğŸ³|ğŸ‘»"),
    ("STRING", r'\\"(.*?)\\"'),
    ("KEYWORD", r"\w+|\p{Emoji}+")
]

IGNORE = ["WHITESPACE", "COMMENT"]



class Token:
    
    def __init__(self, type, value):
        self.type = type
        self.value = value
        
class Tokenizer:
    def __init__(self, code):
        self.tokenized = self.tokenize(code)
        
    def __iter__(self):
        return self
    
    def __next__(self):
        try:
            return self.tokenized.pop()
        except IndexError:
            raise StopIteration
    
    def peek(self):
        return self.tokenized[-1]
       
    def tokenize(self, code):
        code.replace("\"", "\\\"")
        position = 0
        
        tokenized = []
        
        while position < len(code):
            matched = None
            
            for token_type, pattern in tokens:
                reg = regex.compile(pattern)
                matched = reg.match(code, position)
                
                if matched:
                    token_value = matched.group(0)
                    
                    if token_type not in IGNORE and token_value != "\uFE0F":
                        tokenized.append(Token(token_type, token_value))
                    
                    position = matched.end()
                    break
                
            if not matched:
                raise ValueError(f"Unrecognized symbol at {position}: {code[position]}")            

        return tokenized[::-1]


if __name__ == "__main__":
    test = Tokenizer(r"ğŸ™‚ ğŸ“ âš™ï¸ getWordCount â© arg1 âª ğŸŸ° â­ï¸ ğŸ“ ğŸ§® index ğŸŸ° 0 ğŸš« ğŸ“ ğŸ§® count ğŸŸ° 0 ğŸš« ğŸ”„ï¸ (index ğŸ¢ (âš™ï¸ ğŸ“ â© arg1 âª)) â­â” (arg1 ğŸ“Œ index ğŸ” \" \" ) ğŸ‘‰ â­ï¸ count ğŸŸ° count â• 1 ğŸš« â®ï¸ index ğŸŸ° index â• 1 â®ï¸ ğŸ”„ï¸ ğŸš« â†©ï¸ count â®ï¸ ğŸš« ğŸ“ ğŸ§® count ğŸŸ° âš™ï¸ getWordCount â© \"This is my sentence\" âª ğŸš« âš™ï¸ ğŸ‘ï¸ â­ï¸ count â®ï¸ ğŸš« ğŸ˜´")
    for token in test:
        print(f"Type: {token.type}, Value: {token.value}")

